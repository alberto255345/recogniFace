# Anti-Spoofing & Face Recognition API

API leve em **FastAPI** para **liveness (anti-spoofing)** e **reconhecimento facial** (registro/valida√ß√£o) 100% em **CPU**, com detec√ß√£o via **OpenCV DNN**, embeddings via **InsightFace (ONNXRuntime)** e rotas para montar **dataset** e treinar um classificador simples de spoof.

---

## ‚ú® Recursos

* **/v1/liveness**: heur√≠sticas + sinais anti-spoof (blur, alta-freq, anisotropia de grade, glare/reflexo, linhas retas, etc.) com **limiar din√¢mico**, agora aceitando **imagem √∫nica ou clipe curto de v√≠deo**.
* **/v1/register**: liveness ‚ûú embedding (InsightFace) ‚ûú salva em `data/embeddings/{user_id}.npz`.
* **/v1/verify**: liveness ‚ûú embedding ‚ûú compara com cadastro (cosseno), com `match_threshold`.
* **/v1/dataset/upload**: salva imagens rotuladas (`live`/`spoof`) e crops de face para treino.
* **/v1/dataset/stats**: contagem e exemplos do dataset.
* **CPU-first**: roda sem GPU. Se houver GPU compat√≠vel, ONNXRuntime pode usar CUDA (opcional).
* **Logs claros** com `req-id` por chamada.

---

## üß± Arquitetura (resumo)

* **Detec√ß√£o de faces**: OpenCV DNN (SSD/Caffe) com cache de modelo; fallback para HaarCascade.
* **Liveness**: combina√ß√£o de sinais + limiar din√¢mico (piora em ambientes ruins e **endurece** se houver ind√≠cios de spoof).
* **Reconhecimento**: InsightFace `buffalo_l` (w600k\_r50) via ONNXRuntime (providers=CPUExecutionProvider por padr√£o).
* **Dataset**: imagens salvas em `TRAIN_DIR/live|spoof/{raw,faces}`.

---

## ‚úÖ Requisitos

* **Python 3.10+** (recomendado 3.12)
* Sistema com **libGL** para OpenCV (em Ubuntu: `apt-get install -y libgl1`)

### Depend√™ncias principais

```
fastapi
uvicorn
numpy==1.26.4
opencv-python==4.10.0.84
pydantic==2.9.2
python-multipart
python-dotenv
insightface
onnxruntime
joblib
scikit-learn
Pillow==10.4.0
```

> Observa√ß√£o: **TensorFlow/PyTorch n√£o s√£o necess√°rios** para o caminho padr√£o (CPU + ONNXRuntime). Se tiver instalado TF em GPU muito nova, for√ßamos CPU para evitar erros.

---

## üöÄ Instala√ß√£o

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

Se faltar `libgl` no host (para OpenCV):

```bash
# Debian/Ubuntu
sudo apt-get update && sudo apt-get install -y libgl1
```

---

## üîß Configura√ß√£o

Vari√°veis de ambiente √∫teis:

```bash
# Diret√≥rios
export INSIGHTFACE_HOME=/workspace/.insightface   # cache dos modelos do InsightFace
export TRAIN_DIR=/workspace/data/train             # onde salvamos dataset (live/spoof)

# Estabilidade/seguran√ßa de threads (evita segfaults em alguns ambientes)
export OMP_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 MKL_NUM_THREADS=1 NUMEXPR_NUM_THREADS=1

# Desliga warmup de modelos no startup (opcional)
export DISABLE_WARMUP=1

# Classificador ML opcional para spoof (se treinado)
export LIVENESS_CLF_PATH=/workspace/models/liveness_lr.joblib

# Par√¢metros do liveness (pesos e limiares din√¢micos)
export LIVENESS_MIN_SIDE=224
export LIVENESS_W_BLUR=0.35   # pesos positivos
export LIVENESS_W_SAT=0.20
export LIVENESS_W_FREQ=0.45
export LIVENESS_W_AXIS=0.25   # penaliza√ß√µes (spoof)
export LIVENESS_W_GLARE=0.12
export LIVENESS_W_LINES=0.15
export LIVENESS_W_SHARP_SMALL=0.12
export LIVENESS_AXIS_SUSPECT=0.35
export LIVENESS_GLARE_SUSPECT=0.08
export LIVENESS_LINES_SUSPECT=0.10

# Liveness via v√≠deo (amostragem e vota√ß√£o)
export VIDEO_LIVENESS_MAX_FRAMES=24
export VIDEO_LIVENESS_MIN_FRAMES=8
export VIDEO_LIVENESS_PASS_RATIO=0.6
```

> **INSIGHTFACE\_HOME** evita re-download do `buffalo_l` a cada startup.

---

## ‚ñ∂Ô∏è Execu√ß√£o

Para evitar problemas com http2/uvloop em alguns servidores, rode com HTTP/1.1 (`--http h11`):

```bash
uvicorn app.main:app \
  --host 0.0.0.0 --port 8081 \
  --loop asyncio --http h11 --log-level info
```

### Health check

```bash
curl -i http://localhost:8081/health
```

### Expor via Cloudflare Tunnel (opcional)

```bash
# Em outra janela / host
cloudflared tunnel --url http://localhost:8081
# Sa√≠da: https://<algo>.trycloudflare.com  ‚ûú use como BASE nas chamadas
```

---

## üì° Endpoints

### `GET /health`

Retorna status, vers√£o, Python e info b√°sica de CUDA (sempre false no modo CPU).

---

### `POST /v1/liveness`

**Multipart** (`video` para clipes curtos ou `image` para fotos) ou **JSON** (`image_base64`). Par√¢metros opcionais:

* `detector_backend` (padr√£o `opencv`)
* `threshold` (padr√£o `0.5` ‚Äî pode ser dinamicamente ajustado)

```bash
# Multipart (v√≠deo)
curl -s -X POST "$BASE/v1/liveness?detector_backend=opencv&threshold=0.5" \
  -F "video=@/tmp/clip.webm;type=video/webm" | jq

# Multipart (fallback em foto)
curl -s -X POST "$BASE/v1/liveness?detector_backend=opencv&threshold=0.5" \
  -F "image=@$HOME/foto.png;type=image/png" | jq
```

**Resposta**

```json
{
  "faces": [
    {
      "is_live": true,
      "score": 0.707,
      "threshold": 0.50,
      "bbox": {"x":79,"y":367,"w":736,"h":736},
      "extra": {
        "detector_backend": "opencv-dnn",
        "explain": {
          "blur": 1.0,
          "saturation": 0.23,
          "freq_high_ratio": 0.69,
          "axis_anisotropy": 0.12,
          "glare": 0.01,
          "line_ratio": 0.02,
          "penalty_sharp_small": 0.00
        }
      }
    }
  ],
  "latency_ms": 500
}
```

> O **threshold mostrado √© o efetivo**, ap√≥s ajustes din√¢micos (ex.: sobe se detectar sinais de spoof; desce levemente em ambientes dif√≠ceis). Para v√≠deo, o retorno agrega m√∫ltiplos frames (ratio de ‚Äúlive‚Äù vs. ‚Äúspoof‚Äù) e inclui estat√≠sticas em `extra.per_frame`.

---

### `POST /v1/register`

Executa **liveness** (aceitando v√≠deo curto ou foto) e, se aprovado, extrai embedding (InsightFace) da melhor frame para salvar em `data/embeddings/{user_id}.npz`.

Par√¢metros (query/form + multipart):

* `user_id` (obrigat√≥rio)
* `detector_backend` (opcional)
* `threshold` (opcional)

```bash
curl -i --max-time 60 \
  -F "video=@/tmp/clip.webm;type=video/webm" \
  "$BASE/v1/register?user_id=15&detector_backend=opencv&threshold=0.5"
```

**Resposta**

```json
{"success":true,"user_id":"15","liveness_ok":true,"message":"Cadastrado com sucesso"}
```

---

### `POST /v1/verify`

Executa **liveness** (clipe de v√≠deo recomendado) ‚ûú embedding ‚ûú compara c/ cadastro de `user_id`.

Par√¢metros (query/form + multipart):

* `user_id` (obrigat√≥rio)
* `detector_backend`, `threshold` (opcionais)
* `match_threshold` (padr√£o **0.35**, dist√¢ncia cosseno; menor = mais estrito)

```bash
curl -i --max-time 60 \
  -F "video=@/tmp/clip.webm;type=video/webm" \
  "$BASE/v1/verify?user_id=15&detector_backend=opencv&threshold=0.40&match_threshold=0.35"
```

**Resposta** (exemplo)

```json
{
  "success": true,
  "user_id": "15",
  "liveness_ok": true,
  "match": true,
  "cosine_similarity": 0.942,
  "cosine_distance": 0.058,
  "match_threshold": 0.35,
  "message": "OK"
}
```

---

### `POST /v1/dataset/upload`

Salva imagem rotulada e recorte de face para treino.

Query/Form:

* `label`: **live** ou **spoof** (obrigat√≥rio)
* `user_id`: opcional (metadado)
* Aceita tamb√©m `detector_backend` e `threshold` (query ou form) como nas rotas de liveness.

Estrutura de diret√≥rios (padr√£o):

```
$TRAIN_DIR/
  live/
    raw/   # imagem original
    faces/ # crop da face
  spoof/
    raw/
    faces/
```

```bash
# LIVE
curl -s -X POST "$BASE/v1/dataset/upload?label=live&detector_backend=opencv&threshold=0.5" \
  -F "image=@$HOME/foto_real.png;type=image/png" | jq

# SPOOF
a
curl -s -X POST "$BASE/v1/dataset/upload?label=spoof&detector_backend=opencv&threshold=0.5" \
  -F "image=@$HOME/foto2.png;type=image/png" | jq
```

**Resposta** (exemplo)

```json
{
  "success": true,
  "label": "spoof",
  "paths": {"raw": "/workspace/data/train/spoof/raw/....jpg", "face": "/workspace/data/train/spoof/faces/....jpg"},
  "face": {"is_live": false, "score": 0.36, "threshold": 0.50, "bbox": {"x":...,"y":...,"w":...,"h":...}}
}
```

---

### `GET /v1/dataset/stats`

Resumo do dataset constru√≠do.

```bash
curl -s "$BASE/v1/dataset/stats" | jq
```

**Resposta**

```json
{ "total": 123, "live": 70, "spoof": 53, "samples": {"live": ["..."], "spoof": ["..."]} }
```

---

## üß™ Treino de classificador anti-spoof (opcional)

Com as imagens de `TRAIN_DIR/live|spoof/faces`, √© poss√≠vel treinar um **Logistic Regression/SVM** leve em cima das features do liveness. Exemplo de script (fornecido em `scripts/train_liveness.py`):

```bash
python -m scripts.train_liveness --train_dir "$TRAIN_DIR" --out /workspace/models/liveness_lr.joblib
export LIVENESS_CLF_PATH=/workspace/models/liveness_lr.joblib
# reinicie o servidor; o liveness passar√° a usar o modelo como score principal
```

> Mesmo com o classificador, o sistema mant√©m **veto heur√≠stico**: se sinais de spoof forem fortes (anisotropia/glare/linhas), o limiar efetivo **sobe**, tornando a decis√£o mais r√≠gida.

---

## üìù Logs

Formato:

```
2025-09-17 17:08:26,670 INFO api [req=abcd1234] [liveness-core] backend=opencv img=899x1600 thr=0.5
2025-09-17 17:08:26,671 INFO api [req=abcd1234] [liveness-core] face#0 score=0.707 live=True thr_eff=0.50 axis=0.12 glare=0.01 lines=0.02
```

* Defina `--log-level debug` para logs de multipart e detalhes.

---

## üÜò Troubleshooting

* **Re-download de modelos InsightFace a cada start**: defina `INSIGHTFACE_HOME` para um caminho persistente (ex.: `/workspace/.insightface`).
* **Segmentation fault**: use `--http h11`, limite threads (`OMP_NUM_THREADS=1` etc.), e desabilite warmup (`DISABLE_WARMUP=1`). Confira tamb√©m `libgl1` instalado.
* **Nenhum rosto detectado**: use imagens maiores/centradas; aumente `LIVENESS_MIN_SIDE` (ex.: 256); tente `detector_backend=opencv` (√© o padr√£o).
* **Anti-spoof aprovando spoof espec√≠fico**: suba pesos de penaliza√ß√£o (`W_AXIS/GLARE/LINES/SHARP_SMALL`) ou treine um classificador com amostras reais do caso.
* **Verify retornando 404**: garanta que `/v1/register` foi executado para o `user_id` em quest√£o.

---

## üìÑ Licen√ßa

Uso interno / demo. Ajuste conforme a sua necessidade.

---

## üôå Cr√©ditos & Terceiros

* **OpenCV** (detec√ß√£o DNN/HAAR)
* **InsightFace** (embeddings faciais, ONNX)
* **FastAPI / Pydantic**
* **ONNXRuntime**
