<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0"/>
  <title>Biometria Facial</title>
  <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed" rel="stylesheet">
  <style>
    body { margin:0; padding:0; background:#fff; font-family:'Roboto Condensed',sans-serif; font-size:14px; text-align:center;}
    h1 { margin:20px 0; font-size:24px;}
    video { border:3px solid #000; border-radius:6px; margin:15px auto; display:block;}
    input[type="text"], select, input[type="number"]{
      padding:10px; margin:6px; border:1px solid #000; border-radius:4px; font-size:14px; width:240px;
    }
    .row { display:flex; flex-wrap:wrap; gap:10px; align-items:center; justify-content:center; margin:8px 0;}
    .button_base{ margin:8px; font-size:16px; padding:10px 14px; min-width:180px; text-align:center; border:1px solid #000; cursor:pointer; transition:all .2s ease; background:#fff; color:#000; border-radius:6px;}
    .button_base:hover{ background:#000; color:#fff;}
    .btn-green { background:#28a745; color:#fff; border-color:#1d7f35; }
    .btn-green:hover{ background:#1d7f35; }
    .btn-blue { background:#1976d2; color:#fff; border-color:#145aa3; }
    .btn-blue:hover{ background:#145aa3; }
    .btn-red { background:#e53935; color:#fff; border-color:#b71c1c; }
    .btn-red:hover{ background:#b71c1c; }
    #result{ background:#f5f5f5; border:1px solid #ddd; border-radius:4px; padding:15px; margin:20px auto; white-space:pre-wrap; font-family:monospace; width:90%; max-width:1000px; text-align:left;}
    #overlay { position:absolute; border:2px solid #4caf50; border-radius:6px; pointer-events:none; display:none;}
    #stage { position:relative; display:inline-block;}
    .card { border:1px solid #ddd; border-radius:8px; padding:12px; margin:14px auto; max-width:1000px; text-align:left;}
    .card h2 { margin:6px 0 10px 0; font-size:18px; }
    small.muted { color:#666; }
    details { background:#fafafa; border:1px solid #eee; border-radius:8px; padding:10px 12px; margin:12px auto; max-width:1000px; text-align:left;}
    code, pre { background:#f1f1f1; border-radius:6px; padding:4px 6px; }
    pre { overflow:auto; }
    .pill { display:inline-block; padding:2px 8px; border-radius:999px; background:#eee; margin-left:6px; font-size:12px;}
  </style>
</head>
<body>
  <h1>üîê Sistema de Biometria Facial</h1>

  <!-- CONTROLES GERAIS -->
  <div class="card">
    <h2>‚öôÔ∏è Configura√ß√µes</h2>
    <div class="row">
      <label>Detector:
        <select id="detector">
          <option value="opencv" selected>opencv</option>
          <option value="retinaface">retinaface</option>
        </select>
      </label>
      <label>Threshold (liveness):
        <input type="number" id="thr" value="0.50" min="0" max="1" step="0.01">
      </label>
      <label>Match Threshold (verify):
        <input type="number" id="matchThr" value="0.35" min="0" max="1" step="0.01">
      </label>
    </div>
    <small class="muted">Dica: opencv √© mais est√°vel em CPU. Voc√™ pode ajustar os thresholds por aqui sem mexer no backend.</small>
  </div>

  <!-- INSTRU√á√ïES DIN√ÇMICAS -->
  <div id="instructions" class="card" style="border-color:#2196f3;">
    <h2 style="color:#1976d2;">üìã Instru√ß√µes Din√¢micas</h2>
    <div id="dynamic-instructions" style="font-size:16px;font-weight:bold;color:#1976d2;min-height:30px;">
      üéØ Posicione seu rosto na c√¢mera...
    </div>
    <div id="face-status" class="muted">Aguardando detec√ß√£o...</div>
  </div>

  <!-- C√ÇMERA -->
  <div id="stage">
    <video id="video" width="360" height="270" autoplay muted aria-label="C√¢mera"></video>
    <div id="overlay"></div>
  </div>
  <canvas id="canvas" width="360" height="270" style="display:none;"></canvas>

  <!-- ID + A√á√ïES -->
  <div class="card">
    <h2>ü™™ Identifica√ß√£o & A√ß√µes</h2>
    <div class="row">
      <input type="text" id="userId" placeholder="ID do usu√°rio (ex.: 15)" aria-describedby="userId-help" />
      <button class="button_base btn-blue" onclick="capture('register')" aria-label="Cadastrar biometria facial">Cadastrar</button>
      <button class="button_base" onclick="capture('verify')" aria-label="Validar biometria facial">Validar</button>
      <button class="button_base btn-green" onclick="initCamera()" aria-label="Reiniciar c√¢mera">üîÑ Reiniciar C√¢mera</button>
    </div>
    <small id="userId-help" class="muted">Use um identificador √∫nico para cada usu√°rio.</small>
  </div>

  <!-- MODO DATASET (TREINO) -->
  <div class="card">
    <h2>üß™ Modo Dataset (Coleta para Treino) <span class="pill">/v1/dataset/upload</span></h2>
    <div class="row">
      <label><input type="radio" name="label" value="live" checked> live (real)</label>
      <label><input type="radio" name="label" value="spoof"> spoof (ataque)</label>
      <button class="button_base btn-red" onclick="datasetCapture()">üì∏ Enviar amostra ao dataset</button>
      <button class="button_base" onclick="datasetStats()">üìä Estat√≠sticas do dataset</button>
    </div>
    <small class="muted">A amostra √© validada pelo mesmo pipeline (detector/threshold) e salva em <code>$TRAIN_DIR/&lt;label&gt;/{raw,faces}</code>.</small>
  </div>

  <!-- RESULTADOS -->
  <pre id="result"></pre>

  <!-- COMO TREINAR -->
  <details open>
    <summary><strong>üìö Como treinar o classificador de liveness</strong></summary>
    <ol>
      <li>Defina o diret√≥rio base do dataset no servidor:
        <pre><code>export TRAIN_DIR=/workspace/recogniFace/data/train
mkdir -p "$TRAIN_DIR/live/raw"  "$TRAIN_DIR/live/faces"
mkdir -p "$TRAIN_DIR/spoof/raw" "$TRAIN_DIR/spoof/faces"</code></pre>
      </li>
      <li>Use o bloco ‚Äúüß™ Modo Dataset‚Äù acima para enviar v√°rias amostras:
        <ul>
          <li><strong>live</strong>: fotos reais, de pessoas e ambientes reais</li>
          <li><strong.spoof</strong>: fotos de tela, impress√µes, celular exibindo rosto, etc.</li>
        </ul>
      </li>
      <li>Quando tiver quantidade suficiente (ex.: 100+ de cada classe), treine no servidor:
        <pre><code># exemplo (ajuste o caminho se necess√°rio)
python -m scripts.train_liveness \
  --train_dir "$TRAIN_DIR" \
  --out /workspace/models/liveness_lr.joblib</code></pre>
      </li>
      <li>Informe o classificador para a API e reinicie:
        <pre><code>export LIVENESS_CLF_PATH=/workspace/models/liveness_lr.joblib
# (opcional) ajustar pesos/limites das heur√≠sticas:
export LIVENESS_THR_CAP=0.55
export LIVENESS_W_AXIS=0.08 LIVENESS_W_GLARE=0.06 LIVENESS_W_LINES=0.06 LIVENESS_W_SHARP_SMALL=0.05
uvicorn app.main:app --host 0.0.0.0 --port 8081 --loop asyncio --http h11 --log-level info</code></pre>
      </li>
      <li>Valide novamente com casos reais e de spoof para calibrar o threshold.</li>
    </ol>
    <p class="muted">Se quiser, posso te mandar o script <code>scripts/train_liveness</code> prontinho (LR/SVC) usando as features do pipeline.</p>
  </details>

  <script>
    // ===== CONFIG =====
    const API_BASE = "https://signed-conferencing-descending-survivors.trycloudflare.com";
    const ROUTES = {
      liveness: "/v1/liveness",
      register: "/v1/register",
      verify: "/v1/verify",
      datasetUpload: "/v1/dataset/upload",
      datasetStats: "/v1/dataset/stats"
    };

    const VIDEO_DURATION_MS = 2500;

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const context = canvas.getContext('2d');
    const dynamicInstructions = document.getElementById('dynamic-instructions');
    const faceStatus = document.getElementById('face-status');
    const overlay = document.getElementById('overlay');
    const stage = document.getElementById('stage');

    let detectionInterval = null;

    // ===== C√¢mera =====
    function initCamera() {
      stopCamera();
      navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" }, audio: false })
        .then(stream => {
          video.srcObject = stream;
          video.onloadedmetadata = () => {
            video.play();
            startFaceGuidance();
          };
        })
        .catch(err => setResult("Erro ao acessar c√¢mera: " + err.message));
    }
    function stopCamera() {
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(t => t.stop());
        video.srcObject = null;
      }
      stopFaceGuidance();
    }

    // ===== Guia (heur√≠stica simples para UX) =====
    function startFaceGuidance() {
      stopFaceGuidance();
      detectionInterval = setInterval(() => {
        const guide = simpleCenterHeuristic();
        updateDynamicInstructions(guide);
      }, 400);
    }
    function stopFaceGuidance() { if (detectionInterval) clearInterval(detectionInterval); detectionInterval = null; }
    function simpleCenterHeuristic() {
      if (!video.videoWidth || !video.videoHeight) return null;
      const vw = video.videoWidth, vh = video.videoHeight;
      const centerX = vw/2, centerY = vh/2;
      const size = Math.min(vw, vh) * 0.3;
      return { detected: true, centerX, centerY, size, confidence: 0.5 };
    }
    function updateDynamicInstructions(faceData) {
      if (!faceData || !faceData.detected) {
        dynamicInstructions.innerHTML = "üéØ <strong>Posicione seu rosto na c√¢mera</strong>";
        faceStatus.textContent = "Nenhum rosto detectado";
        overlay.style.display = "none";
        return;
      }
      const vw = video.videoWidth, vh = video.videoHeight;
      const cx = faceData.centerX ?? vw/2, cy = faceData.centerY ?? vh/2;
      const size = faceData.size ?? 100;
      const devX = Math.abs(cx - vw/2)/(vw/2);
      const devY = Math.abs(cy - vh/2)/(vh/2);
      const sizeRatio = size/Math.min(vw, vh);

      let instruction = "", status = "";
      if (devX > 0.2) { instruction = cx < vw/2 ? "‚¨ÖÔ∏è <strong>Mova para a direita</strong>" : "‚û°Ô∏è <strong>Mova para a esquerda</strong>"; status="Centralizando..."; }
      else if (devY > 0.2) { instruction = cy < vh/2 ? "‚¨ÜÔ∏è <strong>Mova para baixo</strong>" : "‚¨áÔ∏è <strong>Mova para cima</strong>"; status="Ajustando altura..."; }
      else if (sizeRatio < 0.15) { instruction="üîç <strong>Chegue mais perto</strong>"; status="Rosto pequeno"; }
      else if (sizeRatio > 0.4) { instruction="üîé <strong>Afaste-se</strong>"; status="Rosto grande"; }
      else { instruction="‚úÖ <strong>Perfeito! Mantenha por 2s e capture</strong>"; status="OK"; }

      dynamicInstructions.innerHTML = instruction;
      faceStatus.textContent = status;

      const rect = video.getBoundingClientRect();
      const boxSizePx = Math.min(rect.width, rect.height) * sizeRatio;
      overlay.style.width = boxSizePx + "px";
      overlay.style.height = boxSizePx + "px";
      overlay.style.left = (rect.left + (rect.width - boxSizePx)/2 - stage.getBoundingClientRect().left) + "px";
      overlay.style.top  = (rect.top  + (rect.height - boxSizePx)/2 - stage.getBoundingClientRect().top) + "px";
      overlay.style.display = "block";
    }

    // ===== Helpers =====
    function setResult(txt){ document.getElementById('result').textContent = txt; }

    function readControls() {
      const detector = document.getElementById('detector').value || "opencv";
      const thr = parseFloat(document.getElementById('thr').value || "0.5");
      const matchThr = parseFloat(document.getElementById('matchThr').value || "0.35");
      return { detector, thr, matchThr };
    }

    async function sendToApi(action, media, userId) {
      const { detector, thr, matchThr } = readControls();

      const form = new FormData();
      if (media && media.video) {
        const videoName = media.videoName || `clip_${Date.now()}.webm`;
        form.append("video", media.video, videoName);
      } else if (media && media.image) {
        const imageName = media.imageName || `frame_${Date.now()}.jpg`;
        form.append("image", media.image, imageName);
      } else {
        throw new Error("Nenhum dado de m√≠dia dispon√≠vel.");
      }
      form.append("detector_backend", detector);
      form.append("threshold", String(thr));
      if (action === "verify") form.append("match_threshold", String(matchThr));

      const path = ROUTES[action] || ROUTES.liveness;
      const query = (action === "register" || action === "verify") ? `?user_id=${encodeURIComponent(userId)}` : "";
      const url = `${API_BASE}${path}${query}`;

      try {
        return await fetchJson(url, form);
      } catch (e1) {
        if (detector !== "opencv") {
          console.warn("Falha com detector="+detector+", tentando opencv...", e1);
          form.set("detector_backend", "opencv");
          return await fetchJson(url, form);
        }
        throw e1;
      }
    }

    async function fetchJson(url, formOrNull) {
      const opts = formOrNull ? { method:"POST", body: formOrNull, mode:"cors" } : { method:"GET", mode:"cors" };
      const resp = await fetch(url, opts);
      const txt = await resp.text();
      const maybeJson = safeJson(txt);
      if (!resp.ok) {
        const msg = (maybeJson && maybeJson.detail) ? maybeJson.detail : txt || `HTTP ${resp.status}`;
        throw new Error(msg);
      }
      return maybeJson ?? {};
    }
    function safeJson(s){ try { return JSON.parse(s); } catch { return null; } }

    async function recordVideo(durationMs = VIDEO_DURATION_MS) {
      if (!video.srcObject) throw new Error("C√¢mera n√£o ativa.");
      if (typeof MediaRecorder === "undefined") {
        throw new Error("MediaRecorder n√£o suportado neste navegador.");
      }

      const candidates = [
        "video/webm;codecs=vp9",
        "video/webm;codecs=vp8",
        "video/webm",
        "video/mp4"
      ];
      let chosenMime = "";
      for (const type of candidates) {
        try {
          if (MediaRecorder.isTypeSupported(type)) {
            chosenMime = type;
            break;
          }
        } catch (err) {
          console.warn("MediaRecorder.isTypeSupported falhou", err);
        }
      }

      let recorder;
      try {
        recorder = chosenMime ? new MediaRecorder(video.srcObject, { mimeType: chosenMime }) : new MediaRecorder(video.srcObject);
      } catch (err) {
        console.warn("Falha ao inicializar MediaRecorder com", chosenMime, err);
        recorder = new MediaRecorder(video.srcObject);
        chosenMime = recorder.mimeType || chosenMime;
      }

      const chunks = [];
      return await new Promise((resolve, reject) => {
        recorder.ondataavailable = evt => {
          if (evt.data && evt.data.size > 0) chunks.push(evt.data);
        };
        recorder.onerror = evt => {
          reject(evt && evt.error ? evt.error : new Error("Erro na grava√ß√£o de v√≠deo"));
        };
        recorder.onstop = () => {
          const blobType = chosenMime || recorder.mimeType || "video/webm";
          resolve(new Blob(chunks, { type: blobType }));
        };

        try {
          recorder.start();
        } catch (err) {
          reject(err);
          return;
        }

        setTimeout(() => {
          if (recorder.state !== "inactive") {
            recorder.stop();
          }
        }, durationMs);
      });
    }

    async function captureFrameBlob() {
      const width = video.videoWidth || 360;
      const height = video.videoHeight || 270;
      canvas.width = width;
      canvas.height = height;
      context.drawImage(video, 0, 0, width, height);
      return await new Promise((resolve, reject) => {
        canvas.toBlob(blob => {
          if (blob) resolve(blob);
          else reject(new Error("Falha ao capturar quadro."));
        }, "image/jpeg", 0.9);
      });
    }

    async function capture(action) {
      const userId = (document.getElementById('userId').value || "").trim();
      if ((action === "register" || action === "verify") && !userId) {
        alert("Informe o ID do usu√°rio!"); return;
      }
      if (!video.srcObject) { setResult("Erro: c√¢mera n√£o ativa."); return; }

      // feedback
      const origBorder = video.style.border;
      video.style.border = "3px solid #ff9800";
      setResult(`üé• Gravando v√≠deo (~${(VIDEO_DURATION_MS/1000).toFixed(1)}s)...`);

      await new Promise(r => setTimeout(r, 150));

      const mediaPayload = {};
      try {
        const clip = await recordVideo(VIDEO_DURATION_MS);
        if (clip && clip.size > 0) {
          const extension = clip.type && clip.type.includes("mp4") ? "mp4" : "webm";
          mediaPayload.video = clip;
          mediaPayload.videoName = `clip_${Date.now()}.${extension}`;
        }
      } catch (err) {
        console.warn("Grava√ß√£o de v√≠deo falhou, fallback para foto.", err);
        setResult("‚ö†Ô∏è Falha na grava√ß√£o de v√≠deo, usando foto √∫nica.");
      }

      if (!mediaPayload.video) {
        try {
          const frame = await captureFrameBlob();
          mediaPayload.image = frame;
          mediaPayload.imageName = `frame_${Date.now()}.jpg`;
        } catch (err) {
          setResult("‚ùå Erro ao capturar imagem: " + err.message);
          video.style.border = origBorder || "3px solid #000";
          return;
        }
      }

      setResult("üîÑ Enviando para o servidor...");
      try {
        const data = await sendToApi(action, mediaPayload, userId);
        const lines = [];
        if (action === "register") {
          lines.push(`üßë Usu√°rio: ${userId}`);
          lines.push(`üóÇÔ∏è A√ß√£o: cadastro`);
          lines.push(`üõ°Ô∏è Liveness: ${data.liveness_ok ? "OK" : "REPROVADO"}`);
          lines.push(data.message || (data.success ? "Cadastrado com sucesso." : "Falha no cadastro."));
        } else if (action === "verify") {
          lines.push(`üßë Usu√°rio: ${userId}`);
          lines.push(`üß™ A√ß√£o: verifica√ß√£o`);
          lines.push(`üõ°Ô∏è Liveness: ${data.liveness_ok ? "OK" : "REPROVADO"}`);
          if (data.success) {
            lines.push(`üéØ Match: ${data.match ? "SIM ‚úÖ" : "N√ÉO ‚ùå"}`);
            if (typeof data.cosine_similarity === "number") {
              lines.push(`   cosine_similarity: ${data.cosine_similarity.toFixed(4)}`);
            }
            if (typeof data.cosine_distance === "number") {
              lines.push(`   cosine_distance: ${data.cosine_distance.toFixed(4)} (thr=${data.match_threshold})`);
            }
            if (data.message) lines.push(data.message);
          } else {
            lines.push(data.message || "Falha na verifica√ß√£o.");
          }
        } else {
          lines.push(JSON.stringify(data, null, 2));
        }
        setResult(lines.join("\n"));
      } catch (err) {
        setResult("‚ùå Erro: " + err.message);
      } finally {
        video.style.border = origBorder || "3px solid #000";
      }
    }

    // ===== DATASET =====
    async function datasetCapture() {
      const label = document.querySelector('input[name="label"]:checked').value;
      if (!video.srcObject) { setResult("Erro: c√¢mera n√£o ativa."); return; }

      setResult(`üì∏ Capturando amostra (${label})...`);
      await new Promise(r => setTimeout(r, 200));
      canvas.width = video.videoWidth || 360;
      canvas.height = video.videoHeight || 270;
      context.drawImage(video, 0, 0, canvas.width, canvas.height);
      const blob = await new Promise(resolve => canvas.toBlob(resolve, "image/jpeg", 0.9));

      const { detector, thr } = readControls();
      const url = `${API_BASE}${ROUTES.datasetUpload}?label=${encodeURIComponent(label)}&detector_backend=${encodeURIComponent(detector)}&threshold=${encodeURIComponent(thr)}`;

      const form = new FormData();
      form.append("image", blob, `frame_${Date.now()}.jpg`);

      setResult("üîÑ Enviando amostra ao dataset...");
      try {
        const data = await fetchJson(url, form);
        setResult(`‚úÖ Dataset upload OK\n\n${JSON.stringify(data, null, 2)}`);
      } catch (err) {
        setResult("‚ùå Erro no dataset upload: " + err.message);
      }
    }

    async function datasetStats() {
      setResult("üìä Consultando estat√≠sticas do dataset...");
      try {
        const data = await fetchJson(`${API_BASE}${ROUTES.datasetStats}`);
        setResult(`üìä Dataset stats:\n\n${JSON.stringify(data, null, 2)}`);
      } catch (err) {
        setResult("‚ùå Erro nas estat√≠sticas: " + err.message);
      }
    }

    // boot
    window.addEventListener('load', initCamera);
    window.addEventListener('beforeunload', stopCamera);
  </script>
</body>
</html>
